{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6a4544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import datetime\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d74520",
   "metadata": {},
   "source": [
    "## set up for imports of .py modules by adding path to sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea617f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\disle\\Documents\\Supervised_ML\\final_project\n"
     ]
    }
   ],
   "source": [
    "path = Path(os.getcwd())\n",
    "path = str(path)\n",
    "print(path)\n",
    "sys.path.insert(1, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb57fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.numerical_attr_eda_utils as num_eda_utils\n",
    "import utils.categorical_attr_eda_utils as cat_eda_utils\n",
    "import utils.all_attr_eda_utils as all_attr_eda_utils\n",
    "import utils.attr_eda_utils as attr_eda_utils\n",
    "import utils.assign_and_lab_utils as al_utils\n",
    "import utils.multi_class_target_encoder_utils as mc_te_utils\n",
    "import utils.classification_utils as class_utils\n",
    "import utils.classifier_hyp_param_grid as cl_hpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7251a",
   "metadata": {},
   "source": [
    "## set up to time script run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92dc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372391d",
   "metadata": {},
   "source": [
    "## parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a0a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'data/genetic_disorder.csv'\n",
    "\n",
    "train_test_split_random_state = 42\n",
    "train_validation_split_random_state = 42\n",
    "fast_script_dev = False  \n",
    "model_random_state = 42\n",
    "test_size = 0.20\n",
    "target_attr = 'Genetic Disorder'\n",
    "prediction_task_type = 'classification'\n",
    "sgd_max_iter = 10000\n",
    "binary = False\n",
    "missingness_threshold = 0.20\n",
    "calibrate_classifiers = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b6299",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a453de0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22083, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Id</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Genes in mother's side</th>\n",
       "      <th>Inherited from father</th>\n",
       "      <th>Maternal gene</th>\n",
       "      <th>Paternal gene</th>\n",
       "      <th>Blood cell count (mcL)</th>\n",
       "      <th>Patient First Name</th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Father's name</th>\n",
       "      <th>...</th>\n",
       "      <th>Birth defects</th>\n",
       "      <th>White Blood cell count (thousand per microliter)</th>\n",
       "      <th>Blood test result</th>\n",
       "      <th>Symptom 1</th>\n",
       "      <th>Symptom 2</th>\n",
       "      <th>Symptom 3</th>\n",
       "      <th>Symptom 4</th>\n",
       "      <th>Symptom 5</th>\n",
       "      <th>Genetic Disorder</th>\n",
       "      <th>Disorder Subclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PID0x6418</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.760603</td>\n",
       "      <td>Richard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larre</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.857562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mitochondrial genetic inheritance disorders</td>\n",
       "      <td>Leber's hereditary optic neuropathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PID0x25d5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4.910669</td>\n",
       "      <td>Mike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brycen</td>\n",
       "      <td>...</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>5.522560</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cystic fibrosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PID0x4a82</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4.893297</td>\n",
       "      <td>Kimberly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nashon</td>\n",
       "      <td>...</td>\n",
       "      <td>Singular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Multifactorial genetic inheritance disorders</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PID0x4ac8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.705280</td>\n",
       "      <td>Jeffery</td>\n",
       "      <td>Hoelscher</td>\n",
       "      <td>Aayaan</td>\n",
       "      <td>...</td>\n",
       "      <td>Singular</td>\n",
       "      <td>7.919321</td>\n",
       "      <td>inconclusive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mitochondrial genetic inheritance disorders</td>\n",
       "      <td>Leigh syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PID0x1bf7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.720703</td>\n",
       "      <td>Johanna</td>\n",
       "      <td>Stutzman</td>\n",
       "      <td>Suave</td>\n",
       "      <td>...</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>4.098210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multifactorial genetic inheritance disorders</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Patient Id  Patient Age Genes in mother's side Inherited from father  \\\n",
       "0  PID0x6418          2.0                    Yes                    No   \n",
       "1  PID0x25d5          4.0                    Yes                   Yes   \n",
       "2  PID0x4a82          6.0                    Yes                    No   \n",
       "3  PID0x4ac8         12.0                    Yes                    No   \n",
       "4  PID0x1bf7         11.0                    Yes                    No   \n",
       "\n",
       "  Maternal gene Paternal gene  Blood cell count (mcL) Patient First Name  \\\n",
       "0           Yes            No                4.760603            Richard   \n",
       "1            No            No                4.910669               Mike   \n",
       "2            No            No                4.893297           Kimberly   \n",
       "3           Yes            No                4.705280            Jeffery   \n",
       "4           NaN           Yes                4.720703            Johanna   \n",
       "\n",
       "  Family Name Father's name  ...  Birth defects  \\\n",
       "0         NaN         Larre  ...            NaN   \n",
       "1         NaN        Brycen  ...       Multiple   \n",
       "2         NaN        Nashon  ...       Singular   \n",
       "3   Hoelscher        Aayaan  ...       Singular   \n",
       "4    Stutzman         Suave  ...       Multiple   \n",
       "\n",
       "   White Blood cell count (thousand per microliter) Blood test result  \\\n",
       "0                                          9.857562               NaN   \n",
       "1                                          5.522560            normal   \n",
       "2                                               NaN            normal   \n",
       "3                                          7.919321      inconclusive   \n",
       "4                                          4.098210               NaN   \n",
       "\n",
       "  Symptom 1 Symptom 2 Symptom 3 Symptom 4  Symptom 5  \\\n",
       "0       1.0       1.0       1.0       1.0        1.0   \n",
       "1       1.0       NaN       1.0       1.0        0.0   \n",
       "2       0.0       1.0       1.0       1.0        1.0   \n",
       "3       0.0       0.0       1.0       0.0        0.0   \n",
       "4       0.0       0.0       0.0       0.0        NaN   \n",
       "\n",
       "                               Genetic Disorder  \\\n",
       "0   Mitochondrial genetic inheritance disorders   \n",
       "1                                           NaN   \n",
       "2  Multifactorial genetic inheritance disorders   \n",
       "3   Mitochondrial genetic inheritance disorders   \n",
       "4  Multifactorial genetic inheritance disorders   \n",
       "\n",
       "                     Disorder Subclass  \n",
       "0  Leber's hereditary optic neuropathy  \n",
       "1                      Cystic fibrosis  \n",
       "2                             Diabetes  \n",
       "3                       Leigh syndrome  \n",
       "4                               Cancer  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genetic_df = pd.read_csv(path_to_data)\n",
    "print(genetic_df.shape)\n",
    "genetic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d4732be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop patient Id column\n",
    "genetic_df.drop('Patient Id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f06d24",
   "metadata": {},
   "source": [
    "## drop observations with nans in the target attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44f792",
   "metadata": {},
   "source": [
    "### this can be out of pipeline because when the trained composite estimator predicts on unseen data there is no target attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "731ef04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22083, 44)\n",
      "(19937, 44)\n"
     ]
    }
   ],
   "source": [
    "print(genetic_df.shape)\n",
    "genetic_df = genetic_df.dropna(subset=target_attr)\n",
    "print(genetic_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a23d48",
   "metadata": {},
   "source": [
    "## convert target_attr to numerical encoding using label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18978fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Genes in mother's side</th>\n",
       "      <th>Inherited from father</th>\n",
       "      <th>Maternal gene</th>\n",
       "      <th>Paternal gene</th>\n",
       "      <th>Blood cell count (mcL)</th>\n",
       "      <th>Patient First Name</th>\n",
       "      <th>Family Name</th>\n",
       "      <th>Father's name</th>\n",
       "      <th>Mother's age</th>\n",
       "      <th>...</th>\n",
       "      <th>Birth defects</th>\n",
       "      <th>White Blood cell count (thousand per microliter)</th>\n",
       "      <th>Blood test result</th>\n",
       "      <th>Symptom 1</th>\n",
       "      <th>Symptom 2</th>\n",
       "      <th>Symptom 3</th>\n",
       "      <th>Symptom 4</th>\n",
       "      <th>Symptom 5</th>\n",
       "      <th>Genetic Disorder</th>\n",
       "      <th>Disorder Subclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.760603</td>\n",
       "      <td>Richard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Larre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.857562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Leber's hereditary optic neuropathy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4.893297</td>\n",
       "      <td>Kimberly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nashon</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Singular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Diabetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.705280</td>\n",
       "      <td>Jeffery</td>\n",
       "      <td>Hoelscher</td>\n",
       "      <td>Aayaan</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Singular</td>\n",
       "      <td>7.919321</td>\n",
       "      <td>inconclusive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Leigh syndrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.720703</td>\n",
       "      <td>Johanna</td>\n",
       "      <td>Stutzman</td>\n",
       "      <td>Suave</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>4.098210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>5.103188</td>\n",
       "      <td>Richard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coleston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>10.272230</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cystic fibrosis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient Age Genes in mother's side Inherited from father Maternal gene  \\\n",
       "0          2.0                    Yes                    No           Yes   \n",
       "2          6.0                    Yes                    No            No   \n",
       "3         12.0                    Yes                    No           Yes   \n",
       "4         11.0                    Yes                    No           NaN   \n",
       "5         14.0                    Yes                    No           Yes   \n",
       "\n",
       "  Paternal gene  Blood cell count (mcL) Patient First Name Family Name  \\\n",
       "0            No                4.760603            Richard         NaN   \n",
       "2            No                4.893297           Kimberly         NaN   \n",
       "3            No                4.705280            Jeffery   Hoelscher   \n",
       "4           Yes                4.720703            Johanna    Stutzman   \n",
       "5            No                5.103188            Richard         NaN   \n",
       "\n",
       "  Father's name  Mother's age  ...  Birth defects  \\\n",
       "0         Larre           NaN  ...            NaN   \n",
       "2        Nashon          41.0  ...       Singular   \n",
       "3        Aayaan          21.0  ...       Singular   \n",
       "4         Suave          32.0  ...       Multiple   \n",
       "5      Coleston           NaN  ...       Multiple   \n",
       "\n",
       "  White Blood cell count (thousand per microliter) Blood test result  \\\n",
       "0                                         9.857562               NaN   \n",
       "2                                              NaN            normal   \n",
       "3                                         7.919321      inconclusive   \n",
       "4                                         4.098210               NaN   \n",
       "5                                        10.272230            normal   \n",
       "\n",
       "  Symptom 1 Symptom 2 Symptom 3  Symptom 4  Symptom 5  Genetic Disorder  \\\n",
       "0       1.0       1.0       1.0        1.0        1.0                 0   \n",
       "2       0.0       1.0       1.0        1.0        1.0                 1   \n",
       "3       0.0       0.0       1.0        0.0        0.0                 0   \n",
       "4       0.0       0.0       0.0        0.0        NaN                 1   \n",
       "5       1.0       0.0       0.0        1.0        0.0                 2   \n",
       "\n",
       "                     Disorder Subclass  \n",
       "0  Leber's hereditary optic neuropathy  \n",
       "2                             Diabetes  \n",
       "3                       Leigh syndrome  \n",
       "4                               Cancer  \n",
       "5                      Cystic fibrosis  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "# Encode 'Disorder_subclass'\n",
    "#genetic_df['Disorder_subclass'] = le.fit_transform(genetic_df['Disorder_subclass'])\n",
    "\n",
    "# Encode 'Genetic_disorder'\n",
    "genetic_df['Genetic Disorder'] = le.fit_transform(genetic_df['Genetic Disorder'])\n",
    "genetic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3beac77",
   "metadata": {},
   "source": [
    "## train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc95443",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m train_cap_x_df, train_y_df \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mal_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_the_train_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgenetic_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_test_split_random_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Supervised_ML\\final_project\\utils\\assign_and_lab_utils.py:373\u001b[0m, in \u001b[0;36mperform_the_train_test_split\u001b[1;34m(df, test_size, train_test_split_random_state, prefix, val, stratify)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     stratify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    372\u001b[0m train_cap_x_df, test_cap_x_df, train_y_df, test_y_df \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m--> 373\u001b[0m     \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcap_x_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_test_split_random_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m report_check_split_details_save_data_sets(df, train_cap_x_df, train_y_df, small_set_name, test_cap_x_df, test_y_df,\n\u001b[0;32m    377\u001b[0m                                           prefix, stratify)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m test_cap_x_df, test_y_df\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\base_ds_v4\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\base_ds_v4\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2638\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2634\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2636\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2638\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2641\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2642\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2644\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\base_ds_v4\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2197\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   2165\u001b[0m \n\u001b[0;32m   2166\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2195\u001b[0m \u001b[38;5;124;03m    to an integer.\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2197\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\base_ds_v4\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\base_ds_v4\\lib\\site-packages\\sklearn\\utils\\validation.py:109\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _object_dtype_isnan(X)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 109\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput contains NaN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(X\u001b[38;5;241m.\u001b[39mdtype, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex floating\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "train_cap_x_df, train_y_df = \\\n",
    "    al_utils.perform_the_train_test_split(\n",
    "    genetic_df, \n",
    "    test_size, \n",
    "    train_test_split_random_state, \n",
    "    val=False,\n",
    "    stratify=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114abf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d5e9e",
   "metadata": {},
   "source": [
    "## train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc22aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df, train_y_df = \\\n",
    "    al_utils.perform_the_train_test_split(\n",
    "        pd.concat([train_cap_x_df, train_y_df], axis=1), \n",
    "        test_size, \n",
    "        train_validation_split_random_state, \n",
    "        val=True,\n",
    "        stratify=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a18266",
   "metadata": {},
   "source": [
    "## drop attributes with missingness above threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b5acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingness_drop_list = []\n",
    "for attr in train_cap_x_df.columns:\n",
    "    attr_missingness = train_cap_x_df[attr].isna().sum() / train_cap_x_df.shape[0]\n",
    "    if attr_missingness >= missingness_threshold:\n",
    "        missingness_drop_list.append(attr)\n",
    "\n",
    "missingness_drop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e459d",
   "metadata": {},
   "source": [
    "## identify non machine learning attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46653fe2",
   "metadata": {},
   "source": [
    "### these are attributes that are not meaningful to machine learning - examples include observation identification attributes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6bdb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "concern_list = all_attr_eda_utils.check_for_complete_unique_attrs(train_cap_x_df)\n",
    "print(f'\\nconcern_list:\\n{concern_list}', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ml_attr_list = ['attr_0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e715ae",
   "metadata": {},
   "source": [
    "## identify attributes to drop from machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf0cc41",
   "metadata": {},
   "source": [
    "### these are attributes that were candidates for machine learning but you have chosen to eliminate from machine learning - elimination can be due to vifs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4895f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_attr_drop_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08cc3c8",
   "metadata": {},
   "source": [
    "## establish machine learning attribute configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db47534",
   "metadata": {},
   "source": [
    "#### get all numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.select_dtypes(include=np.number).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc55d8",
   "metadata": {},
   "source": [
    "#### get all object attributes - these are presumed to be nominal attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1b102",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cap_x_df.select_dtypes(include=object).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ebd80e",
   "metadata": {},
   "source": [
    "#### assign the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4eabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_cap_x_df.shape[1]: {train_cap_x_df.shape[1]}')\n",
    "\n",
    "ml_ignore_list = missingness_drop_list + non_ml_attr_list + ml_attr_drop_list\n",
    "print('\\n', ml_ignore_list)\n",
    "\n",
    "nominal_attr = ['attr_3', 'attr_6', 'attr_10', 'attr_12', 'attr_14']\n",
    "print('\\n', nominal_attr)\n",
    "\n",
    "numerical_attr = ['attr_1', 'attr_2', 'attr_4', 'attr_7', 'attr_8', 'attr_9', 'attr_11', 'attr_13', 'attr_15']\n",
    "print('\\n', numerical_attr)\n",
    "\n",
    "assert(train_cap_x_df.shape[1] == len(ml_ignore_list) + len(nominal_attr) + len(numerical_attr))  # got them all?\n",
    "\n",
    "print('\\n', len(numerical_attr) + len(nominal_attr))\n",
    "print('\\n', numerical_attr + nominal_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9bb6ef",
   "metadata": {},
   "source": [
    "## assess target attribute unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6901e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_df[target_attr].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a50fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_df[target_attr].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc05bb9",
   "metadata": {},
   "source": [
    "## steps to deal with unbalanced classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889d035",
   "metadata": {},
   "source": [
    "To be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d91d49",
   "metadata": {},
   "source": [
    "## survey/evaluate default composite estimators with ranking metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ec131",
   "metadata": {},
   "source": [
    "### define the estimators involved in the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925edc53",
   "metadata": {},
   "source": [
    "####  use default instantiations (except for random_state, class_weight and a few others as noted below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744b25e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_names = [\n",
    "    'SGDClassifier', \n",
    "    'DecisionTreeClassifier', \n",
    "    #'RandomForestClassifier', \n",
    "    #'AdaBoostClassifier', \n",
    "    #'GradientBoostingClassifier'\n",
    "]\n",
    "\n",
    "estimator_list = [\n",
    "    \n",
    "    SGDClassifier(loss='log_loss', random_state=model_random_state, class_weight='balanced',\n",
    "                  max_iter=sgd_max_iter),  # logistic regr\n",
    "    \n",
    "    DecisionTreeClassifier(criterion='log_loss', random_state=model_random_state, class_weight='balanced'),\n",
    "    \n",
    "    #RandomForestClassifier(criterion='log_loss', random_state=model_random_state, \n",
    "                       #    class_weight='balanced_subsample'),\n",
    "    \n",
    "#     AdaBoostClassifier(\n",
    "#         estimator=DecisionTreeClassifier(\n",
    "#             criterion='log_loss', \n",
    "#             random_state=model_random_state, \n",
    "#             class_weight='balanced',\n",
    "#             max_depth=1\n",
    "#         ),\n",
    "#         random_state=model_random_state\n",
    "#     ),\n",
    "    \n",
    "#     GradientBoostingClassifier(loss='log_loss', random_state=model_random_state),\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee0c13a",
   "metadata": {},
   "source": [
    "### fit the default default models and evaluate performance on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3ef54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# class_eval_dict:\n",
    "#    key = name of function in classification_utils.py\n",
    "#    value = [bool, function kwargs]  bool = True then call function\n",
    "print_plots = False\n",
    "class_eval_dict={\n",
    "    'binary': binary,\n",
    "    'scoring': 'average_precision',\n",
    "    'get_precision_recall_curves': [True, \n",
    "                                    {'print_prc': print_plots, \n",
    "                                     'print_prd': print_plots,\n",
    "                                    }],\n",
    "    'get_roc_curve': [True, \n",
    "                      {\n",
    "                        'print_roc': print_plots,\n",
    "                      }]\n",
    "}\n",
    "\n",
    "default_train_compare_df, trained_default_estimator_dict = \\\n",
    "    al_utils.fit_collection_of_estimators(\n",
    "        numerical_attr, \n",
    "        nominal_attr, \n",
    "        estimator_names, \n",
    "        estimator_list, \n",
    "        train_cap_x_df, \n",
    "        train_y_df, \n",
    "        data_set_type='train', \n",
    "        model_selection_stage='default',\n",
    "        prediction_task_type='classification',\n",
    "        class_eval_dict=class_eval_dict\n",
    ")\n",
    "default_train_compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5ff89",
   "metadata": {},
   "source": [
    "### evaluate the performance of the trained default estimators on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d91264",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('validation_df.csv').set_index(keys='index')\n",
    "validation_df.index.name = None\n",
    "validation_cap_x_df, validation_y_df = validation_df.iloc[:, :-1], validation_df.iloc[:, -1].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce2706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_eval_dict:\n",
    "#    key = name of function in classification_utils.py\n",
    "#    value = [bool, function kwargs]  bool = True then call function\n",
    "print_plots = False\n",
    "class_eval_dict={\n",
    "    'binary': binary,\n",
    "    'scoring': 'average_precision',\n",
    "    'get_precision_recall_curves': [True, \n",
    "                                    {'print_prc': print_plots, \n",
    "                                     'print_prd': print_plots,\n",
    "                                    }],\n",
    "    'get_roc_curve': [True, \n",
    "                      {\n",
    "                        'print_roc': print_plots,\n",
    "                      }]\n",
    "}\n",
    "\n",
    "\n",
    "default_validation_compare_df = al_utils.eval_trained_estimators_in_trained_estimator_dict_class(\n",
    "    trained_default_estimator_dict, \n",
    "    validation_cap_x_df, \n",
    "    validation_y_df, \n",
    "    data_set_type='validation',\n",
    "    model_selection_stage='default', \n",
    "    class_eval_dict=class_eval_dict\n",
    ")\n",
    "default_validation_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c14915",
   "metadata": {},
   "outputs": [],
   "source": [
    "del validation_cap_x_df, validation_y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2a53d",
   "metadata": {},
   "source": [
    "### assemble a data frame of default estimator performance on the train and validation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.concat([default_train_compare_df, default_validation_compare_df], axis=0).\\\n",
    "    sort_values(['estimator', 'data_set_type', 'model_selection_stage'])\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316e796",
   "metadata": {},
   "source": [
    "### check out vifs of the design matrices for the default models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eea677",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "al_utils.check_out_vifs_of_preprocessed_design_matrices_of_a_collection_of_trained_estimators(\n",
    "    trained_default_estimator_dict, \n",
    "    train_cap_x_df, \n",
    "    data_set_type='train',\n",
    "    model_selection_stage='default_instantiation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e6ca7b",
   "metadata": {},
   "source": [
    "## short list composite estimators based on default estimator findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb345be7",
   "metadata": {},
   "source": [
    "To be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08ac501",
   "metadata": {},
   "source": [
    "## hyperparameters tuning on default models using GridSearchCV with ranking metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b6fdb",
   "metadata": {},
   "source": [
    "### design the hyperparameter tuning experiment to select the best model by populating the parameter grid with hyperparameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f14e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_points = 5\n",
    "l1_ratio_points = 5\n",
    "m_points = 5\n",
    "\n",
    "hyp_param_tuning_exp_dict = cl_hpg.get_hyp_param_tuning_exp_dict(\n",
    "    estimator_names,\n",
    "    estimator_list, \n",
    "    alpha_points, \n",
    "    l1_ratio_points, \n",
    "    m_points, \n",
    "    train_cap_x_df, \n",
    "    binary=True,\n",
    "    fast_script_dev=fast_script_dev, \n",
    "    print_param_grids=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faade996",
   "metadata": {},
   "source": [
    "### perform a grid search over hyper parameters to select best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d3764",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_eval_dict:\n",
    "#    key = name of function in classification_utils.py\n",
    "#    value = [bool, function kwargs]  bool = True then call function\n",
    "print_plots = False\n",
    "class_eval_dict={\n",
    "    'binary': binary,\n",
    "    'scoring': 'average_precision',\n",
    "    'get_precision_recall_curves': [True, \n",
    "                                    {'print_prc': print_plots, \n",
    "                                     'print_prd': print_plots,\n",
    "                                     'data_set_name': '',  # this is here to make things work - a bit of a hack\n",
    "                                     'model_selection_stage': '',  # this is here to make things work - a bit of \n",
    "                                                                   # a hack\n",
    "                                    }],\n",
    "    'get_roc_curve': [True, \n",
    "                      {\n",
    "                        'print_roc': print_plots,\n",
    "                        'data_set_name': '',  # this is here to make things work - a bit of a hack\n",
    "                        'model_selection_stage': '',  # this is here to make things work - a bit of a hack\n",
    "                      }]\n",
    "}\n",
    "\n",
    "grid_search_cv_results_df, _ = \\\n",
    "    al_utils.grid_search_cv_wrapper(\n",
    "        estimator_names,\n",
    "        hyp_param_tuning_exp_dict, \n",
    "        numerical_attr, \n",
    "        nominal_attr,\n",
    "        train_cap_x_df, \n",
    "        train_y_df, \n",
    "        target_attr,\n",
    "        prediction_task_type='classification',\n",
    "        class_eval_dict=class_eval_dict\n",
    ")\n",
    "grid_search_cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b7037",
   "metadata": {},
   "source": [
    "## evaluate tuned composite estimators with ranking metrics - bootstrapping (no refit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829fe779",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('validation_df.csv').set_index(keys='index')\n",
    "validation_df.index.name = None\n",
    "validation_cap_x_df, validation_y_df = validation_df.iloc[:, :-1], validation_df.iloc[:, -1].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c3bfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_eval_dict:\n",
    "#    key = name of function in classification_utils.py\n",
    "#    value = [bool, function kwargs]  bool = True then call function\n",
    "print_plots = False\n",
    "class_eval_dict={\n",
    "    'binary': binary,\n",
    "    'scoring': 'average_precision',\n",
    "    'get_precision_recall_curves': [True, \n",
    "                                    {'print_prc': print_plots, \n",
    "                                     'print_prd': print_plots,\n",
    "                                    }],\n",
    "    'get_roc_curve': [True, \n",
    "                      {\n",
    "                        'print_roc': print_plots,\n",
    "                      }]\n",
    "}\n",
    "\n",
    "_ = \\\n",
    "    al_utils.execute_and_plot_bootstrap_eval_without_refit(\n",
    "        estimator_names,\n",
    "        grid_search_cv_results_df,\n",
    "        validation_cap_x_df, \n",
    "        validation_y_df,\n",
    "        num_bs_samples=20,\n",
    "        model_selection_stage='tuned_instantiation',\n",
    "        data_set_type='validation_set',\n",
    "        prediction_task_type='classification',\n",
    "        class_eval_dict=class_eval_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7906dbf",
   "metadata": {},
   "source": [
    "### visualize the model performance using ranking metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ed2fe9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_perf_dict = \\\n",
    "    class_utils.ranking_metrics_class_perf_assess_binary(\n",
    "        estimator_names, \n",
    "        grid_search_cv_results_df, \n",
    "        validation_cap_x_df, \n",
    "        validation_y_df, \n",
    "        classification_threshold=0.50, \n",
    "        cvs_compute=False, \n",
    "        cvs_print=False,\n",
    "        data_set_name='validation', \n",
    "        model_selection_stage='tuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce39b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "del validation_cap_x_df, validation_y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f1d36f",
   "metadata": {},
   "source": [
    "## calibrate the composite estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_classifiers:\n",
    "    validation_df = pd.read_csv('validation_df.csv').set_index(keys='index')\n",
    "    validation_df.index.name = None\n",
    "    validation_cap_x_df, validation_y_df = validation_df.iloc[:, :-1], validation_df.iloc[:, -1].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759afff",
   "metadata": {},
   "source": [
    "#### split off some of the validation set for calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42441d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_classifiers:\n",
    "    cal_split_size = 0.50\n",
    "    cal_split_random_state = 21\n",
    "\n",
    "    cal_cap_x_df, cal_y_df, validation_cap_x_df, validation_y_df = al_utils.split_validation_for_calibration(\n",
    "        pd.concat([validation_cap_x_df, validation_y_df], axis=1),\n",
    "        cal_split_size=cal_split_size,\n",
    "        cal_split_random_state=cal_split_random_state\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29d193",
   "metadata": {},
   "source": [
    "#### perform the calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1db12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if calibrate_classifiers:\n",
    "    # class_eval_dict:\n",
    "    #    key = name of function in classification_utils.py\n",
    "    #    value = [bool, function kwargs]  bool = True then call function\n",
    "    print_plots = False\n",
    "    class_eval_dict={\n",
    "        'binary': binary,\n",
    "        'scoring': 'average_precision',\n",
    "        'get_precision_recall_curves': [True, \n",
    "                                        {'print_prc': print_plots, \n",
    "                                         'print_prd': print_plots,\n",
    "                                        }],\n",
    "        'get_roc_curve': [True, \n",
    "                          {\n",
    "                            'print_roc': print_plots,\n",
    "                          }]\n",
    "    }\n",
    "\n",
    "    sig_cal_grid_search_cv_results_df = al_utils.calibrate_estimators(\n",
    "        estimator_names, \n",
    "        grid_search_cv_results_df, \n",
    "        pd.concat([train_cap_x_df, cal_cap_x_df], axis=0),\n",
    "        pd.concat([train_y_df, cal_y_df], axis=0),\n",
    "        validation_cap_x_df, \n",
    "        validation_y_df,\n",
    "        class_eval_dict=class_eval_dict,\n",
    "        calibration_data_set_name='probability calibration', \n",
    "        validation_data_set_name='validation',\n",
    "        model_selection_stage='tuned', \n",
    "        method='isotonic',  # 'sigmoid' or 'isotonic'\n",
    "        ensemble=True\n",
    "    )\n",
    "\n",
    "    estimator_names = al_utils.get_estimator_names_helper(grid_search_cv_results_df, \n",
    "                                                          sig_cal_grid_search_cv_results_df)\n",
    "    grid_search_cv_results_df = pd.concat([sig_cal_grid_search_cv_results_df, grid_search_cv_results_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_classifiers:\n",
    "    del cal_cap_x_df, cal_y_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_classifiers:\n",
    "    del validation_cap_x_df, validation_y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7b0b62",
   "metadata": {},
   "source": [
    "## check for false discoveries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b0e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('validation_df.csv').set_index(keys='index')\n",
    "validation_df.index.name = None\n",
    "validation_cap_x_df, validation_y_df = validation_df.iloc[:, :-1], validation_df.iloc[:, -1].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ae9fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class_eval_dict:\n",
    "#    key = name of function in classification_utils.py\n",
    "#    value = [bool, function kwargs]  bool = True then call function\n",
    "print_plots = False\n",
    "class_eval_dict={\n",
    "    'binary': binary,\n",
    "    'scoring': 'average_precision',\n",
    "    'get_precision_recall_curves': [True, \n",
    "                                    {'print_prc': print_plots, \n",
    "                                     'print_prd': print_plots,\n",
    "                                    }],\n",
    "    'get_roc_curve': [True, \n",
    "                      {\n",
    "                        'print_roc': print_plots,\n",
    "                      }]\n",
    "}\n",
    "\n",
    "al_utils.avoiding_false_discoveries_class(\n",
    "    estimator_names, \n",
    "    grid_search_cv_results_df, \n",
    "    train_cap_x_df, \n",
    "    train_y_df, \n",
    "    validation_cap_x_df, \n",
    "    validation_y_df, \n",
    "    num_samples=20, \n",
    "    class_eval_dict=class_eval_dict,\n",
    "    data_set_name='validation', \n",
    "    model_selection_stage='tuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ff563",
   "metadata": {},
   "outputs": [],
   "source": [
    "del validation_cap_x_df, validation_y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6421869f",
   "metadata": {},
   "source": [
    "## time to execute to this point in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f397ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "print(f'script run time: {(end - start)/60} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78828bf",
   "metadata": {},
   "source": [
    "## stop notebook execution and select a model to promote if there is more then one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(estimator_names) > 1:\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c5e5e",
   "metadata": {},
   "source": [
    "## select a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6639fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03043682",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = 'cal_iso_T_DecisionTreeClassifier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_names = [best_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4fbe0",
   "metadata": {},
   "source": [
    "## permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0149d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_imp_dict, _ = \\\n",
    "    al_utils.permutation_importance_helper(\n",
    "        estimator_names, \n",
    "        grid_search_cv_results_df, \n",
    "        train_cap_x_df, \n",
    "        train_y_df, \n",
    "        scoring = ['average_precision', 'roc_auc'],\n",
    "        stop_reporting_threshold=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9ecea",
   "metadata": {},
   "source": [
    "## tune classification threshold for classification with classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e6b53",
   "metadata": {},
   "source": [
    "### select the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3e505e",
   "metadata": {},
   "source": [
    "### check out the classifier as a function of classification threshold - select the classfication threshold at which the classifier will operated to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f311a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('validation_df.csv').set_index(keys='index')\n",
    "validation_df.index.name = None\n",
    "validation_cap_x_df, validation_y_df = validation_df.iloc[:, :-1], validation_df.iloc[:, -1].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682db17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_threshold_list = np.arange(0, 1.1, 0.1)\n",
    "thresh_class_perf_dict = \\\n",
    "    class_utils.class_thresh_metrics_class_perf_assess_binary(\n",
    "        best_model, \n",
    "        estimator_names, \n",
    "        grid_search_cv_results_df, \n",
    "        validation_cap_x_df, \n",
    "        validation_y_df, \n",
    "        class_threshold_list, \n",
    "        cvs_compute=False, \n",
    "        cvs_print=False, \n",
    "        data_set_name='validation', \n",
    "        model_selection_stage='tuned'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229bd059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_threshold_list = np.arange(0, 1.01, 0.01)\n",
    "class_utils.plot_errors_as_a_function_of_classification_threshold(\n",
    "    best_model, \n",
    "    estimator_names, \n",
    "    grid_search_cv_results_df,\n",
    "    validation_cap_x_df, \n",
    "    validation_y_df, \n",
    "    class_threshold_list, \n",
    "    data_set_name='validation',\n",
    "    model_selection_stage='tuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65398b6d",
   "metadata": {},
   "source": [
    "### set the classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7632a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_threshold = 0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f600f551",
   "metadata": {},
   "source": [
    "### use bootstrapping to understand how the precision will vary at this classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c7b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_utils.precision_recall_bootstrap_no_refit_binary(\n",
    "    estimator_names, \n",
    "    grid_search_cv_results_df,\n",
    "    validation_cap_x_df,\n",
    "    validation_y_df, \n",
    "    n_bootstrap=20,\n",
    "    data_set_name='validation', \n",
    "    model_selection_stage='tuned',\n",
    "    classification_threshold=classification_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f514e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_utils.roc_curve_bootstrap_no_refit_binary(\n",
    "    estimator_names, \n",
    "    grid_search_cv_results_df, \n",
    "    validation_cap_x_df, \n",
    "    validation_y_df, \n",
    "    n_bootstrap=20,\n",
    "    data_set_name='validation', \n",
    "    model_selection_stage='tuned',\n",
    "    classification_threshold=classification_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037cf05",
   "metadata": {},
   "source": [
    "### can we do better? higher resolution scan of classification threshold around selected classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9be3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = classification_threshold - 0.05\n",
    "stop = classification_threshold + 0.06\n",
    "step_size = 0.01\n",
    "\n",
    "class_threshold_list = np.arange(start, stop, step_size)\n",
    "thresh_class_perf_dict = \\\n",
    "    class_utils.class_thresh_metrics_class_perf_assess_binary(\n",
    "        best_model, \n",
    "        estimator_names, \n",
    "        grid_search_cv_results_df, \n",
    "        validation_cap_x_df, \n",
    "        validation_y_df, \n",
    "        class_threshold_list, \n",
    "        cvs_compute=False, \n",
    "        cvs_print=False, \n",
    "        data_set_name='validation', \n",
    "        model_selection_stage='tuned'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267ab1e",
   "metadata": {},
   "source": [
    "### examine some classifier evaluations to better understand how the classiifcation metrics vary with classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bfade",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = \\\n",
    "    grid_search_cv_results_df.loc[grid_search_cv_results_df.estimator == best_model, 'best_estimator'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54489133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_perf_dict = class_utils.classification_performance(\n",
    "    best_estimator, \n",
    "    validation_cap_x_df, \n",
    "    validation_y_df.values.ravel(), \n",
    "    classification_threshold=classification_threshold,\n",
    "    binary=True,\n",
    "    # https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    cvs_scoring_dict={\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision': 'precision',\n",
    "        'recall': 'recall',\n",
    "        'f1': 'f1'\n",
    "    },\n",
    "    cr_digits=4,\n",
    "    cr_print=True,  # print classification report\n",
    "    cm_print=True,  # print confusion matrix\n",
    "    cvs_compute=False,  # compute cross_val_scores (classification threshold = 0.5 always)\n",
    "    cvs_print=True,  # print cross_val_scores (classification threshold = 0.5 always) - ignored if cvs_compute=False\n",
    "    prc_print=True,  # print precision and recall curves as a function of classification threshold\n",
    "    prd_print=True,  # print precision recall curves\n",
    "    roc_print=True,  # print roc curve\n",
    "    data_set_name='validation', \n",
    "    model_selection_stage='tuned'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e86903",
   "metadata": {},
   "outputs": [],
   "source": [
    "del validation_cap_x_df, validation_y_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7ed3eb",
   "metadata": {},
   "source": [
    "## serialize model and classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd385a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "date_time_prefix = str(now).replace('-', '_').replace(' ', '_').replace(':', '_').replace('.', '_')[:-4]\n",
    "\n",
    "date_time_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator_file_name = date_time_prefix + '_cancer_screening_model' + '.pkl'\n",
    "\n",
    "best_estimator_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_estimator = \\\n",
    "    grid_search_cv_results_df.loc[grid_search_cv_results_df.estimator == best_model, 'best_estimator'].iloc[0]\n",
    "\n",
    "model_dict = {\n",
    "    'classification_threshold': classification_threshold,\n",
    "    'best_model': best_model,\n",
    "    'composite_estimator': best_estimator\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(best_estimator_file_name, 'wb') as f:\n",
    "    pickle.dump(model_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e7c6ad",
   "metadata": {},
   "source": [
    "## evaluate model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e84b1",
   "metadata": {},
   "source": [
    "This should be done in an independent notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base_ds_v4)",
   "language": "python",
   "name": "base_ds_v4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
